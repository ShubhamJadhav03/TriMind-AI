import operator
from dotenv import load_dotenv
from pathlib import Path
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
from typing import Annotated
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, add_messages, END
from langgraph.prebuilt import ToolNode
from datetime import datetime
from langgraph.prebuilt import InjectedState
from utils import truncate_messages

load_dotenv()

# Load the copywriter system prompt and content examples
copywriter_prompt = open("prompts/copywriter.md", "r").read()
linkedin_example = open("example_content/linkedin.md", "r").read()
blog_example = open("example_content/blog.md", "r").read()


def _sanitize_title(title: str) -> str:
    """Convert a title into a safe filename stem."""
    sanitized = "".join(
        char if char.isalnum() or char in {" ", "-", "_"} else "_"
        for char in title
    ).strip()
    sanitized = "_".join(filter(None, sanitized.split()))
    return sanitized or "generated_content"


class CopyWriterState(BaseModel):
    """The state of the copywriter agent. 
    
    The research_reports attribute is shared with the supervisor state. This allows the supervisor to access the research reports generated by the researcher and share them with the copywriter.
    """
    messages: Annotated[list, add_messages] = []
    research_reports: Annotated[list, operator.add] = []


@tool
async def review_research_reports(
    state: Annotated[CopyWriterState, InjectedState],
):
    """Use this tool to review available research reports to inform your writing.
    
    Returns:
        A list of research reports.
    """
    return [report.model_dump_json() for report in state.research_reports]

@tool
async def generate_linkedin_post(
    title: str,
    content: str,
):
    """Use this tool to generate a LinkedIn post.
    
    Args:
        title: The title of the post.
        content: The content of the post in markdown format.

    Returns:
        A string indicating the location of the saved post.
    """
    sanitized_title = _sanitize_title(title)
    file_path = Path("ai_files") / f"{sanitized_title}.md"
    file_path.parent.mkdir(parents=True, exist_ok=True)
    file_path.write_text(content, encoding="utf-8")

    return f"The LinkedIn post has been generated and saved to {file_path.as_posix()}"

@tool
async def generate_blog_post(
    title: str,
    content: str,
):
    """Use this tool to generate a blog post.
    
    Args:
        title: The title of the post.
        content: The content of the post in markdown format.

    Returns:
        A string indicating the location of the saved post.
    """
    sanitized_title = _sanitize_title(title)
    file_path = Path("ai_files") / f"{sanitized_title}.md"
    file_path.parent.mkdir(parents=True, exist_ok=True)
    file_path.write_text(content, encoding="utf-8")

    return f"The blog post has been generated and saved to {file_path.as_posix()}"

llm = ChatOpenAI(
    name="CopyWriter",
    model="gpt-4o-mini",
)

tools=[
    review_research_reports,
    generate_linkedin_post, 
    generate_blog_post
    ]
llm_with_tools = llm.bind_tools(tools)

async def copywriter(state: CopyWriterState):
    """The main copywriter agent."""
    # Create system message
    system_prompt = SystemMessage(content=copywriter_prompt.format(
        current_datetime=datetime.now(),
        linkedin_example=linkedin_example,
        blog_example=blog_example,
        ))
    
    # Truncate messages to prevent token limit issues
    # Keep max 10 messages + system message to stay well under 200k TPM rate limit
    truncated_messages = truncate_messages(
        messages=state.messages,
        system_message=system_prompt,
        max_messages=10,
        max_tokens_approx=100000,  # Stay well under 200k TPM limit per request
    )
    
    response = llm_with_tools.invoke(truncated_messages)
    return {"messages": [response]}

async def copywriter_router(state: CopyWriterState) -> str:
    """Route to the tools node if the copywriter makes a tool call."""
    if state.messages[-1].tool_calls:
        return "tools"
    return END

builder = StateGraph(CopyWriterState)

builder.add_node(copywriter)
builder.add_node("tools", ToolNode(tools))

builder.set_entry_point("copywriter")

builder.add_conditional_edges(
    "copywriter",
    copywriter_router,
    {
        "tools": "tools",
        END: END,
    }
)
builder.add_edge("tools", "copywriter")

# Don't use a checkpointer if using as a subgraph, the parent graph's checkpointer will be inherited
graph = builder.compile()

# graph = builder.compile(checkpointer=MemorySaver())


# Visualize the graph
# from IPython.display import Image
# Image(graph.get_graph().draw_mermaid_png())
